{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Literal, Tuple, Union\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "model_channels=360\n",
    "out_channels = 3\n",
    "num_res_blocks=2\n",
    "channel_mult=[1,2,4,4]\n",
    "resolution=None\n",
    "attn_resolutions=[4,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        resample: Literal['default', 'up', 'down'] = 'default',\n",
    "        groups: int = 32,\n",
    "        eps: float = 1e-5,\n",
    "        skip_scale: float = 1, # multiplied to output\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.skip_scale = skip_scale\n",
    "\n",
    "        self.norm1 = nn.GroupNorm(num_groups=groups, num_channels=in_channels, eps=eps, affine=True)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.norm2 = nn.GroupNorm(num_groups=groups, num_channels=out_channels, eps=eps, affine=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.act = F.silu\n",
    "\n",
    "        self.resample = None\n",
    "        if resample == 'up':\n",
    "            self.resample = partial(F.interpolate, scale_factor=2.0, mode=\"nearest\")\n",
    "        elif resample == 'down':\n",
    "            self.resample = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.shortcut = nn.Identity()\n",
    "        if self.in_channels != self.out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        if self.resample:\n",
    "            res = self.resample(res)\n",
    "            x = self.resample(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        x = (x + self.shortcut(res)) * self.skip_scale\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int = 1,\n",
    "        downsample: bool = True,\n",
    "        skip_scale: float = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    " \n",
    "        nets = []\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else out_channels\n",
    "            nets.append(ResnetBlock(in_channels, out_channels, skip_scale=skip_scale))\n",
    "        self.nets = nn.ModuleList(nets)\n",
    "\n",
    "        self.downsample = None\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = []\n",
    "\n",
    "        for net in self.nets:\n",
    "            x = net(x)\n",
    "            xs.append(x)\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "            xs.append(x)\n",
    "  \n",
    "        return x, xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_layers: int = 1,\n",
    "        skip_scale: float = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        nets = []\n",
    "        attns = []\n",
    "        # first layer\n",
    "        nets.append(ResnetBlock(in_channels, in_channels, skip_scale=skip_scale))\n",
    "        # more layers\n",
    "        for i in range(num_layers):\n",
    "            nets.append(ResnetBlock(in_channels, in_channels, skip_scale=skip_scale))\n",
    "        self.nets = nn.ModuleList(nets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.nets[0](x)\n",
    "        for net in  self.nets[1:]:\n",
    "            x = net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        prev_out_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int = 1,\n",
    "        upsample: bool = True,\n",
    "        skip_scale: float = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        nets = []\n",
    "        for i in range(num_layers):\n",
    "            cin = in_channels if i == 0 else out_channels\n",
    "            cskip = prev_out_channels if (i == num_layers - 1) else out_channels\n",
    "\n",
    "            nets.append(ResnetBlock(cin + cskip, out_channels, skip_scale=skip_scale))\n",
    "        self.nets = nn.ModuleList(nets)\n",
    "\n",
    "        self.upsample = None\n",
    "        if upsample:\n",
    "            self.upsample = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, xs):\n",
    "\n",
    "        for net in self.nets:\n",
    "            res_x = xs[-1]\n",
    "            xs = xs[:-1]\n",
    "            x = torch.cat([x, res_x], dim=1)\n",
    "            x = net(x)\n",
    "            \n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
    "            x = self.upsample(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianUnet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=14,\n",
    "                 out_channels=14,\n",
    "                 down_channels=(64, 128, 256, 512, 1024),\n",
    "                 up_channels=(1024, 512, 256, 128, 64),\n",
    "                 layer_per_block=2,\n",
    "                 skip_scale=np.sqrt(0.5),):\n",
    "        super().__init__()\n",
    "        self.conv_in=nn.Conv1d(in_channels,down_channels[0],kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        down_blocks=[]\n",
    "        cout=down_channels[0]\n",
    "        for i in range(len(down_channels)):\n",
    "            cin=cout\n",
    "            cout=down_channels[i]\n",
    "            down_blocks.append(DownBlock(\n",
    "                in_channels=cin,\n",
    "                out_channels=cout,\n",
    "                downsample=(i!=len(down_channels)-1),\n",
    "                num_layers=layer_per_block,\n",
    "                skip_scale=skip_scale,\n",
    "            ))\n",
    "        self.down_blocks=nn.ModuleList(down_blocks)\n",
    "\n",
    "        self.mid_block=MidBlock(\n",
    "            in_channels=down_channels[-1],\n",
    "            skip_scale=skip_scale,\n",
    "        )\n",
    "\n",
    "        up_blocks=[]\n",
    "        cout=up_channels[0]\n",
    "        for i in range(len(up_channels)):\n",
    "            cin=cout\n",
    "            cskip = down_channels[max(-2 - i, -len(down_channels))]\n",
    "            cout=up_channels[i]\n",
    "            up_blocks.append(UpBlock(\n",
    "                in_channels=cin,\n",
    "                prev_out_channels=cskip,\n",
    "                out_channels=cout,\n",
    "                upsample=(i!=len(up_channels)-1),\n",
    "                num_layers=layer_per_block+1,\n",
    "                skip_scale=skip_scale,\n",
    "            ))\n",
    "        self.up_blocks=nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.norm_out=nn.GroupNorm(num_channels=up_channels[-1], num_groups=32, eps=1e-5)\n",
    "        self.conv_out=nn.Conv1d(up_channels[-1],out_channels,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, Cin, H, W]\n",
    "\n",
    "        # first\n",
    "        x = self.conv_in(x)\n",
    "        \n",
    "        # down\n",
    "        xss = [x]\n",
    "        for block in self.down_blocks:\n",
    "            x, xs = block(x)\n",
    "            xss.extend(xs)\n",
    "        \n",
    "        # mid\n",
    "        x = self.mid_block(x)\n",
    "\n",
    "        # up\n",
    "        for block in self.up_blocks:\n",
    "            xs = xss[-len(block.nets):]\n",
    "            xss = xss[:-len(block.nets)]\n",
    "            x = block(x, xs)\n",
    "\n",
    "        # last\n",
    "        x = self.norm_out(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.conv_out(x) # [B, Cout, H', W']\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
